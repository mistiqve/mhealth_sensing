{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing ##\n",
    "\n",
    "- read location, accelerometer and heart rate data files\n",
    "- resample by second\n",
    "- get PID #9 data, output to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_folder = \"/Users/Fyxstkala/Documents/GitHub/mhealth_sensing/data/\" # ROOT FOLDER CHANGE THIS\n",
    "\n",
    "hr_file = data_folder + \"Smartwatch_HeartRateDatum.csv\"\n",
    "acc_file = data_folder + \"Sensus_Accelerometer.csv\"\n",
    "loc_file = data_folder + \"Sensus_Location.csv\"\n",
    "hr_out_file = data_folder + \"hr_data.csv\"\n",
    "acc_out_file = data_folder + \"acc_data.csv\"\n",
    "loc_out_file = data_folder + \"loc_data.csv\"\n",
    "combined_file = data_folder + \"combined_data_outer.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process HR File\n",
    "\n",
    "for chunk in pd.read_csv(hr_file, header = 0, chunksize=10**6):\n",
    "    chunk['Timestamp'] = pd.to_datetime(chunk['Timestamp'],\n",
    "                                    origin=\"unix\", \n",
    "                                    errors=\"coerce\")\n",
    "    chunk = chunk[[\"participantid\",\"HR\",\"Timestamp\"]]\n",
    "    chunk.columns =[\"PID\",\"HR\",\"Timestamp\"] # reset column name\n",
    "    chunk[['HR','PID']]=  chunk[['HR','PID']].apply(pd.to_numeric,\n",
    "                                                    errors='coerce', downcast = \"float\") # change variable type\n",
    "    chunk.set_index(['Timestamp'], inplace=True) # set timestamp as index \n",
    "    chunk = chunk.resample(\"S\").mean().reset_index() # resample by second\n",
    "    print(chunk.shape)\n",
    "    chunk = chunk.loc[chunk['PID'] == 9.0]\n",
    "    with open(hr_out_file, 'a') as f:\n",
    "        chunk.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Accelerometer File\n",
    "\n",
    "for chunk in pd.read_csv(acc_file, header = 0, chunksize=10**6):\n",
    "    chunk['Timestamp'] = pd.to_datetime(chunk['Timestamp'],\n",
    "                                    origin=\"unix\", \n",
    "                                    errors=\"coerce\")\n",
    "    chunk = chunk[[\"ParticipantId\",\"X\",\"Y\",\"Z\",\"Timestamp\"]]\n",
    "    chunk.columns = [\"PID\",\"X\",\"Y\",\"Z\",\"Timestamp\"] # reset column name\n",
    "    chunk[['PID','X','Y','Z']] = chunk[['PID','X','Y','Z']].apply(pd.to_numeric,\n",
    "                                                errors='coerce', downcast = \"float\") # change var type\n",
    "    chunk.set_index(['Timestamp'], inplace=True) # set timestamp as index \n",
    "    chunk = chunk.resample(\"S\").mean().reset_index() # resample by second\n",
    "    print(chunk.shape)\n",
    "    chunk = chunk.loc[chunk['PID'] == 9.0]\n",
    "    with open(acc_out_file, 'a') as f:\n",
    "        chunk.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Location File\n",
    "\n",
    "for chunk in pd.read_csv(loc_file, header = 0, chunksize=10**6):\n",
    "    chunk['Timestamp'] = pd.to_datetime(chunk['Timestamp'],\n",
    "                                    origin=\"unix\", \n",
    "                                    errors=\"coerce\")\n",
    "    chunk = chunk[[\"ParticipantId\",\"Latitude\",\"Longitude\",\"Timestamp\"]]\n",
    "    chunk.columns =[\"PID\",\"Latitude\",\"Longitude\",\"Timestamp\"] # reset column name\n",
    "    # change variable type\n",
    "    chunk[['Latitude','Longitude','PID']]=  chunk[['Latitude','Longitude','PID']].apply(pd.to_numeric, \n",
    "                                                                                        errors='coerce', \n",
    "                                                                                        downcast = \"float\") \n",
    "    chunk.set_index(['Timestamp'], inplace=True) # set timestamp as index \n",
    "    chunk = chunk.resample(\"S\").mean().reset_index() # resample by second\n",
    "    print(chunk.shape)\n",
    "    chunk = chunk.loc[chunk['PID'] == 9.0]\n",
    "    with open(loc_out_file, 'a') as f:\n",
    "        chunk.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating Files\n",
    "\n",
    "- aggregate all three files to one (keep NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_datetime(df):\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'],\n",
    "                                     origin=\"unix\",\n",
    "                                     errors=\"coerce\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313598, 4)\n"
     ]
    }
   ],
   "source": [
    "hr_df = pd.read_csv(hr_out_file, header = None)\n",
    "hr_df.columns = [\"index\",\"Timestamp\",\"PID\",\"HR\"]\n",
    "hr_df = set_datetime(hr_df)\n",
    "print(hr_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23016115, 6)\n"
     ]
    }
   ],
   "source": [
    "acc_df = pd.read_csv(acc_out_file, header = None)\n",
    "acc_df.columns = [\"index\",\"Timestamp\",\"PID\",\"X\",\"Y\",\"Z\"]\n",
    "acc_df = set_datetime(acc_df)\n",
    "print(acc_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1375778, 5)\n"
     ]
    }
   ],
   "source": [
    "loc_df = pd.read_csv(loc_out_file, header = None)\n",
    "loc_df.columns = [\"index\",\"Timestamp\",\"PID\",\"Latitude\",\"Longitude\"]\n",
    "loc_df = set_datetime(loc_df)\n",
    "print(loc_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index           Timestamp  PID     HR\n",
      "0  28200976 2018-11-02 00:26:39  9.0  115.0\n",
      "1  28205935 2018-11-02 01:49:18  9.0  102.0\n",
      "2  28205986 2018-11-02 01:50:09  9.0  108.0\n",
      "3  28205995 2018-11-02 01:50:18  9.0  107.5\n",
      "4  28206373 2018-11-02 01:56:36  9.0   91.0\n",
      "    index           Timestamp  PID   Latitude  Longitude\n",
      "0   72820 2018-11-02 15:15:07  9.0  38.030903 -78.510900\n",
      "1   86228 2018-11-02 18:58:35  9.0  38.030674 -78.505630\n",
      "2  262258 2018-11-04 19:52:25  9.0  38.057487 -78.501270\n",
      "3  262485 2018-11-04 19:56:12  9.0  38.057484 -78.501250\n",
      "4  263118 2018-11-04 20:06:45  9.0  38.049034 -78.508675\n",
      "   index           Timestamp  PID         X         Y         Z\n",
      "0   8826 2018-11-01 22:25:48  9.0  0.015261 -0.005453 -0.988026\n",
      "1   8827 2018-11-01 22:25:49  9.0  0.014712 -0.005540 -0.988052\n",
      "2   8828 2018-11-01 22:25:50  9.0  0.015244 -0.005294 -0.987978\n",
      "3   8829 2018-11-01 22:25:51  9.0  0.015270 -0.005137 -0.988068\n",
      "4   8830 2018-11-01 22:25:52  9.0  0.014770 -0.005396 -0.988174\n"
     ]
    }
   ],
   "source": [
    "print(hr_df[:5])\n",
    "print(loc_df[:5])\n",
    "print(acc_df[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23172085, 9)\n"
     ]
    }
   ],
   "source": [
    "hr_acc_df = pd.merge(hr_df, acc_df, how=\"outer\", on=\"Timestamp\")\n",
    "print(hr_acc_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200875551, 13)\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.merge(hr_acc_df, loc_df, how=\"outer\", on=\"Timestamp\")\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200875551, 8)\n",
      "(536982, 8)\n",
      "               Timestamp     HR         X         Y         Z  PID   Latitude  \\\n",
      "0    2018-11-02 00:26:39  115.0       NaN       NaN       NaN  NaN        NaN   \n",
      "1    2018-11-02 01:49:18  102.0  0.100423 -0.564653 -0.796036  9.0  38.008865   \n",
      "404  2018-11-02 01:50:09  108.0  0.059478 -1.005974  0.237641  9.0  38.014576   \n",
      "807  2018-11-02 01:50:18  107.5  0.060751 -0.670354 -0.669088  9.0  38.015583   \n",
      "1210 2018-11-02 01:56:36   91.0 -0.100375  0.973441  0.210622  9.0  38.018010   \n",
      "\n",
      "      Longitude  \n",
      "0           NaN  \n",
      "1    -78.527040  \n",
      "404  -78.525856  \n",
      "807  -78.525020  \n",
      "1210 -78.521300  \n"
     ]
    }
   ],
   "source": [
    "combined_df = combined_df.drop(columns=['index_x','index_y','index','PID_x','PID_y'])\n",
    "print(combined_df.shape)\n",
    "combined_df = combined_df.drop_duplicates()\n",
    "print(combined_df.shape)\n",
    "print(combined_df[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(combined_file, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
